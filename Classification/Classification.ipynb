{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2IJJzZPQz8x"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# BLOCK 0- COLAB SETUP (Install)\n",
        "# =========================\n",
        "!pip -q install pymupdf openai tqdm pandas requests\n",
        "\n",
        "import os, re, json, glob, time\n",
        "from typing import Dict, Any, Optional, Tuple, List\n",
        "\n",
        "import fitz  # PyMuPDF\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BLOCK (1) GATHER & EXTRACT PAPERS\n",
        "# =========================\n",
        "\n",
        "# --- In Colab, put PDFs here ---\n",
        "PDF_DIR = \"/content/pdfs\"  # create this folder and upload PDFs\n",
        "\n",
        "MAX_PAGES_TO_READ = 10\n",
        "MAX_CHARS_PER_PAPER = 14000\n",
        "\n",
        "# Create folder if missing\n",
        "os.makedirs(PDF_DIR, exist_ok=True)\n",
        "\n",
        "# =========================\n",
        "# PDF extraction helpers\n",
        "# =========================\n",
        "SECTION_HEADERS = [\"abstract\",\"introduction\",\"methods\",\"materials and methods\",\"participants\",\"results\",\"discussion\",\"conclusion\",\"references\"]\n",
        "\n",
        "def _normalize(s: str) -> str:\n",
        "    s = s.replace(\"\\u00ad\", \"\")\n",
        "    s = re.sub(r\"[ \\t]+\", \" \", s)\n",
        "    s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str, max_pages: int) -> str:\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pages = []\n",
        "    for i in range(min(max_pages, doc.page_count)):\n",
        "        page = doc.load_page(i)\n",
        "\n",
        "        t = page.get_text(\"text\").strip()\n",
        "        if t:\n",
        "            pages.append(t)\n",
        "            continue\n",
        "\n",
        "        blocks = page.get_text(\"blocks\")\n",
        "        block_text = \"\\n\".join(\n",
        "            b[4] for b in blocks\n",
        "            if len(b) > 4 and isinstance(b[4], str) and b[4].strip()\n",
        "        ).strip()\n",
        "        if block_text:\n",
        "            pages.append(block_text)\n",
        "\n",
        "    doc.close()\n",
        "    return _normalize(\"\\n\".join(pages))\n",
        "\n",
        "def extract_title_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Heuristic title extraction:\n",
        "    - Uses the first page\n",
        "    - Takes the first non-empty line with sufficient length\n",
        "    - Avoids author lists / affiliations when possible\n",
        "    \"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        page = doc.load_page(0)\n",
        "\n",
        "        text = page.get_text(\"text\")\n",
        "        doc.close()\n",
        "\n",
        "        if not text:\n",
        "            return \"UNKNOWN_TITLE\"\n",
        "\n",
        "        lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "\n",
        "        for line in lines[:10]:\n",
        "            if len(line) > 20 and not re.search(r\"(university|department|email|@)\", line, re.I):\n",
        "                return line\n",
        "\n",
        "        return lines[0] if lines else \"UNKNOWN_TITLE\"\n",
        "\n",
        "    except Exception:\n",
        "        return \"UNKNOWN_TITLE\"\n",
        "\n",
        "def find_section_span(text: str, start_kw: str) -> Optional[Tuple[int, int]]:\n",
        "    start_pat = re.compile(rf\"(?im)^\\s*{re.escape(start_kw)}\\s*[:\\n]\", re.MULTILINE)\n",
        "    m = start_pat.search(text)\n",
        "    if not m:\n",
        "        return None\n",
        "    start = m.end()\n",
        "    other = [h for h in SECTION_HEADERS if h != start_kw.lower()]\n",
        "    end_pat = re.compile(r\"(?im)^\\s*(\" + \"|\".join(map(re.escape, other)) + r\")\\s*[:\\n]\", re.MULTILINE)\n",
        "    m2 = end_pat.search(text[start:])\n",
        "    end = start + m2.start() if m2 else len(text)\n",
        "    return start, end\n",
        "\n",
        "def grab(text: str, header: str) -> str:\n",
        "    span = find_section_span(text, header)\n",
        "    if not span:\n",
        "        return \"\"\n",
        "    s, e = span\n",
        "    return _normalize(text[s:e])\n",
        "\n",
        "def extract_AMR(text: str) -> Dict[str, str]:\n",
        "    abstract = grab(text, \"Abstract\")\n",
        "    methods = grab(text, \"Methods\") or grab(text, \"Materials and Methods\") or grab(text, \"Participants\")\n",
        "    results = grab(text, \"Results\")\n",
        "    return {\"abstract\": abstract, \"methods\": methods, \"results\": results}\n",
        "\n",
        "def build_model_input(sections: Dict[str, str], raw_text: str) -> Tuple[str, str]:\n",
        "    methods = sections.get(\"methods\", \"\").strip()\n",
        "    results = sections.get(\"results\", \"\").strip()\n",
        "    abstract = sections.get(\"abstract\", \"\").strip()\n",
        "\n",
        "    if methods or results:\n",
        "        parts = []\n",
        "        if methods:\n",
        "            parts.append(\"Methods:\\n\" + methods)\n",
        "        if results:\n",
        "            parts.append(\"Results:\\n\" + results)\n",
        "        used = \"methods+results\"\n",
        "        text = \"\\n\\n\".join(parts)\n",
        "\n",
        "    elif abstract:\n",
        "        used = \"abstract_only\"\n",
        "        text = \"Abstract:\\n\" + abstract\n",
        "\n",
        "    else:\n",
        "        used = \"fallback_fulltext\"\n",
        "        text = raw_text\n",
        "\n",
        "    text = text[:MAX_CHARS_PER_PAPER].strip()\n",
        "    return text, used\n"
      ],
      "metadata": {
        "id": "qhLL-rY7RAcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BLOCK(2) SCREEN & CLASSIFY PAPERS\n",
        "#    - Local LLM (Ollama) OR GPT model\n",
        "# =========================\n",
        "\n",
        "# ---------- ROUTING CONFIG ----------\n",
        "OLLAMA_URL = \"http://127.0.0.1:11434/api/chat\"\n",
        "OLLAMA_MODEL = \"llama3:latest\"  # change if needed\n",
        "\n",
        "OPENAI_MODEL = \"gpt-5.2\"\n",
        "client = OpenAI()  # uses OPENAI_API_KEY env var\n",
        "\n",
        "OUT_CSV = \"eeg_hybrid_results.csv\"\n",
        "\n",
        "# =========================\n",
        "# GPT RUBRIC PROMPT (Full rubric)\n",
        "# =========================\n",
        "RUBRIC = r\"\"\"\n",
        "You are an expert scientific screening and classification system for EEG papers.\n",
        "Your task is to classify one scientific paper into exactly one of the following categories based strictly on the Methods and Results sections (do not rely on the abstract alone unless no other text is available). You must not infer, assume, or guess. Only use explicitly stated information in the provided text.\n",
        "\n",
        "ðŸŽ¯ Classification Categories (Final Output Label) Choose one and only one:\n",
        "1. Irrelevant â†’ The paper fails any relevance criterion in Step 1.\n",
        "2. Relevant-without-psychometrics â†’ The paper passes Step 1, but does not report psychometric properties of single-trial EEG estimates.\n",
        "3. Relevant-with-psychometrics â†’ The paper passes Step 1 and explicitly reports psychometric properties of single-trial EEG estimates.\n",
        "\n",
        "ðŸ§ª Step 1: Relevance Screening (MANDATORY) The paper must satisfy ALL:\n",
        "1) Single-trial EEG reporting:\n",
        "A. Single-trial / within-person variability:\n",
        "\"Single-trial\" OR \"Single trial\" OR \"Within-person\" OR \"Within person\" OR \"Within-subject\" OR \"Within subject\" OR\n",
        "\"Trial-wise\" OR \"Trial wise\" OR \"Trial-by-trial\" OR \"Trial by trial\" OR \"Varia*\" OR \"Vary*\" OR \"Fluctuation*\" OR \"Intra*\"\n",
        "B. EEG / electrophysiology:\n",
        "\"EEG\" OR \"ERP\" OR \"Event-related potential\" OR \"Evoked potential\" OR \"Electroencephalogra*\" OR \"Electrophysiology\"\n",
        "Important constraints:\n",
        "â€¢ â€œEEGâ€ and â€œERPâ€ must appear as stand-alone tokens or within parentheses\n",
        "â€¢ Do not count substrings (e.g., â€œeegâ€ inside another word)\n",
        "\n",
        "2) Human participants: explicitly human\n",
        "3) Non-clinical sample: explicitly healthy / non-patient\n",
        "\n",
        "If any Step 1 criterion fails â†’ Irrelevant and record which criteria failed.\n",
        "\n",
        "ðŸ§  Step 2: Psychometrics Screening (ONLY if Step 1 passes)\n",
        "If psychometric keywords appear anywhere in Methods or Results, mark psychometrics_reported true and list keywords.\n",
        "Important note: do not decide whether psychometrics refer to EEG or questionnaires yet. If keyword appears anywhere in Methods or Results include and flag for manual checking.\n",
        "\n",
        "Psychometrics keywords include:\n",
        "Reliability, Validity, Test theory, Test-retest, Parallel-forms, Split-half, Odd-even, Internal consistency, Consistency,\n",
        "Intraclass correlation, ICC, Cronbach, Generalizability theory, G-theory, Generalizability coefficient, G-coefficient,\n",
        "G-study, D-study, Dependability, Index of dependability, Variance components, Variance decomposition, Stability,\n",
        "Invariance, Non-invariance, Measurement error, Error components, Latent state trait theory, LSTT, Empirical decomposition,\n",
        "Specificity, Spearman-Brown, Bland-Altman, Construct validity, Content validity, Convergent validity, Discriminant validity,\n",
        "Factorial validity, Criterion validity, Differential item functioning, Dimensionality, Multidimensional, Discrimination power, Difficulty\n",
        "\n",
        "ðŸ—‚ï¸ Required Output Format (STRICT JSON)\n",
        "Return ONLY valid JSON. No extra text.\n",
        "\n",
        "{\n",
        " \"final_classification\": \"Irrelevant | Relevant-without-psychometrics | Relevant-with-psychometrics\",\n",
        " \"step1_relevance\": {\n",
        "   \"single_trial_EEG\": true,\n",
        "   \"human_participants\": true,\n",
        "   \"non_clinical_sample\": true,\n",
        "   \"failed_criteria\": []\n",
        " },\n",
        " \"step2_psychometrics\": {\n",
        "   \"psychometrics_reported\": true,\n",
        "   \"matched_keywords\": [\"ICC\", \"Test-retest\"]\n",
        " },\n",
        " \"evidence_notes\": {\n",
        "   \"single_trial_EEG_evidence\": \"exact sentence or phrase\",\n",
        "   \"human_sample_evidence\": \"exact sentence or phrase\",\n",
        "   \"non_clinical_evidence\": \"exact sentence or phrase\",\n",
        "   \"psychometrics_evidence\": \"exact sentence or phrase or 'not reported'\"\n",
        " }\n",
        "}\n",
        "\n",
        "ðŸš« Hard Rules:\n",
        "- Do not infer intent or methodology\n",
        "- Do not use background knowledge\n",
        "- Do not normalize or paraphrase evidence\n",
        "- If information is unclear â†’ treat as not reported\n",
        "- Always prefer false negatives over false positives\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "GzApv6eVRDzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BLOCK (3) ASSIGN LABELS: Irrelevant vs Relevant (prompt logic)\n",
        "#     + hard keyword verification for Step 1 evidence\n",
        "# =========================\n",
        "\n",
        "# =========================\n",
        "# Schemas\n",
        "# =========================\n",
        "OLLAMA_STEP1_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"single_trial_EEG\": {\"type\": \"boolean\"},\n",
        "        \"human_participants\": {\"type\": \"boolean\"},\n",
        "        \"non_clinical_sample\": {\"type\": \"boolean\"},\n",
        "        \"failed_criteria\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "        \"evidence\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"single_trial_EEG_evidence\": {\"type\": \"string\"},\n",
        "                \"human_sample_evidence\": {\"type\": \"string\"},\n",
        "                \"non_clinical_evidence\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"single_trial_EEG_evidence\", \"human_sample_evidence\", \"non_clinical_evidence\"],\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"single_trial_EEG\", \"human_participants\", \"non_clinical_sample\", \"failed_criteria\", \"evidence\"],\n",
        "}\n",
        "\n",
        "OPENAI_SCHEMA = {\n",
        "    \"type\": \"object\",\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"final_classification\": {\n",
        "            \"type\": \"string\",\n",
        "            \"enum\": [\"Irrelevant\", \"Relevant-without-psychometrics\", \"Relevant-with-psychometrics\"],\n",
        "        },\n",
        "        \"step1_relevance\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"single_trial_EEG\": {\"type\": \"boolean\"},\n",
        "                \"human_participants\": {\"type\": \"boolean\"},\n",
        "                \"non_clinical_sample\": {\"type\": \"boolean\"},\n",
        "                \"failed_criteria\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            },\n",
        "            \"required\": [\"single_trial_EEG\", \"human_participants\", \"non_clinical_sample\", \"failed_criteria\"],\n",
        "        },\n",
        "        \"step2_psychometrics\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"psychometrics_reported\": {\"type\": \"boolean\"},\n",
        "                \"matched_keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "            },\n",
        "            \"required\": [\"psychometrics_reported\", \"matched_keywords\"],\n",
        "        },\n",
        "        \"evidence_notes\": {\n",
        "            \"type\": \"object\",\n",
        "            \"additionalProperties\": False,\n",
        "            \"properties\": {\n",
        "                \"single_trial_EEG_evidence\": {\"type\": \"string\"},\n",
        "                \"human_sample_evidence\": {\"type\": \"string\"},\n",
        "                \"non_clinical_evidence\": {\"type\": \"string\"},\n",
        "                \"psychometrics_evidence\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"single_trial_EEG_evidence\",\n",
        "                \"human_sample_evidence\",\n",
        "                \"non_clinical_evidence\",\n",
        "                \"psychometrics_evidence\",\n",
        "            ],\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"final_classification\", \"step1_relevance\", \"step2_psychometrics\", \"evidence_notes\"],\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Keyword checks (hard verification)\n",
        "# =========================\n",
        "SINGLE_TRIAL_PATTERNS = [\n",
        "    r\"\\bsingle[-\\s]?trial\\b\",\n",
        "    r\"\\btrial[-\\s]?by[-\\s]?trial\\b\",\n",
        "    r\"\\btrial[-\\s]?wise\\b\",\n",
        "    r\"\\bwithin[-\\s]?person\\b\",\n",
        "    r\"\\bwithin[-\\s]?subject\\b\",\n",
        "    r\"\\bintra\\w*\\b\",\n",
        "    r\"\\bfluctuation\\w*\\b\",\n",
        "    r\"\\bvariab\\w*\\b\",\n",
        "    r\"\\bvary\\w*\\b\",\n",
        "]\n",
        "\n",
        "EEG_ERP_TOKEN = re.compile(r\"(?i)(?:\\bEEG\\b|\\bERP\\b|\\(EEG\\)|\\(ERP\\))\")\n",
        "\n",
        "def has_single_trial(text: str) -> bool:\n",
        "    t = text.lower()\n",
        "    return any(re.search(p, t) for p in SINGLE_TRIAL_PATTERNS)\n",
        "\n",
        "def has_eeg_token(text: str) -> bool:\n",
        "    return EEG_ERP_TOKEN.search(text) is not None or re.search(r\"(?i)\\belectroencephalograph\\w*\\b\", text) is not None\n",
        "\n",
        "def looks_human(text: str) -> bool:\n",
        "    t = text.lower()\n",
        "    return any(x in t for x in [\"participants\", \"subjects\", \"healthy adults\", \"humans\", \"volunteers\", \"students\", \"years old\", \"men\", \"women\"])\n",
        "\n",
        "def looks_non_clinical(text: str) -> bool:\n",
        "    t = text.lower()\n",
        "    return any(x in t for x in [\"healthy\", \"non-clinical\", \"nonclinical\", \"no history of\", \"no psychiatric\", \"control group\"])\n",
        "\n",
        "def evidence_is_verifiable(step1: Dict[str, Any]) -> bool:\n",
        "    ev = step1.get(\"evidence\", {})\n",
        "    st = ev.get(\"single_trial_EEG_evidence\", \"\") or \"\"\n",
        "    hu = ev.get(\"human_sample_evidence\", \"\") or \"\"\n",
        "    nc = ev.get(\"non_clinical_evidence\", \"\") or \"\"\n",
        "\n",
        "    if not (has_single_trial(st) and has_eeg_token(st)):\n",
        "        return False\n",
        "    if not looks_human(hu):\n",
        "        return False\n",
        "    if not looks_non_clinical(nc):\n",
        "        return False\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "duQWAuAHRHMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BLOCK (4) REVIEW & ANALYZE RESULTS\n",
        "#     - Call models\n",
        "#     - Decide route\n",
        "#     - Build rows for CSV\n",
        "# =========================\n",
        "\n",
        "# =========================\n",
        "# Ollama Step1 prompt + call\n",
        "# =========================\n",
        "OLLAMA_STEP1_PROMPT = r\"\"\"\n",
        "You are an expert screening system for EEG papers.\n",
        "Task: Perform ONLY Step 1 (relevance) using the provided text. Do not infer or guess.\n",
        "\n",
        "Step 1 passes only if ALL are explicitly supported:\n",
        "1) Single-trial EEG reporting: provide evidence containing BOTH:\n",
        "   - a single-trial / trial-by-trial / within-person / within-subject / intra- / variability / fluctuation concept\n",
        "   - AND an EEG/ERP/electroencephalography/electrophysiology term\n",
        "   Note: EEG/ERP must appear as standalone token or in parentheses.\n",
        "2) Human participants: explicit.\n",
        "3) Non-clinical sample: explicit healthy/non-patient.\n",
        "\n",
        "Output MUST match the JSON schema exactly.\n",
        "\n",
        "Return:\n",
        "- single_trial_EEG (boolean)\n",
        "- human_participants (boolean)\n",
        "- non_clinical_sample (boolean)\n",
        "- failed_criteria: list of strings among:\n",
        "  [\"single_trial_EEG\", \"human_participants\", \"non_clinical_sample\"] that are false.\n",
        "- evidence:\n",
        "  - single_trial_EEG_evidence: exact sentence/phrase (must include both single-trial concept and EEG/ERP/etc)\n",
        "  - human_sample_evidence: exact sentence/phrase\n",
        "  - non_clinical_evidence: exact sentence/phrase\n",
        "\n",
        "Text:\n",
        "{paper_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "def ollama_step1(paper_text: str) -> Dict[str, Any]:\n",
        "    payload = {\n",
        "        \"model\": OLLAMA_MODEL,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a strict JSON generator. Output only valid JSON.\"},\n",
        "            {\"role\": \"user\", \"content\": OLLAMA_STEP1_PROMPT.format(paper_text=paper_text)},\n",
        "        ],\n",
        "        \"stream\": False,\n",
        "        \"format\": OLLAMA_STEP1_SCHEMA,\n",
        "        \"options\": {\"temperature\": 0}\n",
        "    }\n",
        "\n",
        "    r = requests.post(OLLAMA_URL, json=payload, timeout=300)\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"Ollama HTTP {r.status_code}: {r.text[:300]}\")\n",
        "\n",
        "    data = r.json()\n",
        "    content = data[\"message\"][\"content\"].strip()\n",
        "    return json.loads(content)\n",
        "\n",
        "# =========================\n",
        "# OpenAI calls\n",
        "# =========================\n",
        "def openai_full_classify(paper_text: str) -> Dict[str, Any]:\n",
        "    resp = client.responses.create(\n",
        "        model=OPENAI_MODEL,\n",
        "        instructions=RUBRIC,\n",
        "        input=f\"Paper text:\\n{paper_text}\",\n",
        "        text={\n",
        "            \"format\": {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"name\": \"EEGScreeningResult\",\n",
        "                \"schema\": OPENAI_SCHEMA,\n",
        "                \"strict\": True\n",
        "            }\n",
        "        },\n",
        "    )\n",
        "    return json.loads(resp.output_text)\n",
        "\n",
        "def openai_step2_only(paper_text: str, step1: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    prompt = f\"\"\"\n",
        "You must TRUST the following Step 1 results as already verified by code and do NOT re-evaluate Step 1.\n",
        "Use them exactly as given and fill in Step 2 (psychometrics) + final_classification accordingly.\n",
        "Return STRICT JSON with the same schema.\n",
        "\n",
        "Verified Step 1 (do not change):\n",
        "{json.dumps({\n",
        "  \"single_trial_EEG\": step1[\"single_trial_EEG\"],\n",
        "  \"human_participants\": step1[\"human_participants\"],\n",
        "  \"non_clinical_sample\": step1[\"non_clinical_sample\"],\n",
        "  \"failed_criteria\": step1[\"failed_criteria\"],\n",
        "  \"evidence\": step1[\"evidence\"]\n",
        "}, ensure_ascii=False)}\n",
        "\n",
        "Paper text:\n",
        "{paper_text}\n",
        "\"\"\".strip()\n",
        "\n",
        "    resp = client.responses.create(\n",
        "        model=OPENAI_MODEL,\n",
        "        instructions=\"Return ONLY valid JSON that matches the schema exactly.\",\n",
        "        input=prompt,\n",
        "        text={\n",
        "            \"format\": {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"name\": \"EEGScreeningResult\",\n",
        "                \"schema\": OPENAI_SCHEMA,\n",
        "                \"strict\": True\n",
        "            }\n",
        "        },\n",
        "    )\n",
        "\n",
        "    out = json.loads(resp.output_text)\n",
        "\n",
        "    out[\"step1_relevance\"] = {\n",
        "        \"single_trial_EEG\": step1[\"single_trial_EEG\"],\n",
        "        \"human_participants\": step1[\"human_participants\"],\n",
        "        \"non_clinical_sample\": step1[\"non_clinical_sample\"],\n",
        "        \"failed_criteria\": step1[\"failed_criteria\"],\n",
        "    }\n",
        "    out[\"evidence_notes\"][\"single_trial_EEG_evidence\"] = step1[\"evidence\"][\"single_trial_EEG_evidence\"]\n",
        "    out[\"evidence_notes\"][\"human_sample_evidence\"] = step1[\"evidence\"][\"human_sample_evidence\"]\n",
        "    out[\"evidence_notes\"][\"non_clinical_evidence\"] = step1[\"evidence\"][\"non_clinical_evidence\"]\n",
        "\n",
        "    return out\n",
        "\n",
        "# =========================\n",
        "# Utility functions (for CSV columns)\n",
        "# =========================\n",
        "def yn(flag: Any) -> str:\n",
        "    if flag is None:\n",
        "        return \"\"\n",
        "    if isinstance(flag, bool):\n",
        "        return \"Y\" if flag else \"N\"\n",
        "    s = str(flag).strip().lower()\n",
        "    if s in {\"y\", \"yes\", \"true\", \"1\"}:\n",
        "        return \"Y\"\n",
        "    if s in {\"n\", \"no\", \"false\", \"0\"}:\n",
        "        return \"N\"\n",
        "    return str(flag)\n",
        "\n",
        "def is_sent_to_gpt(route: str) -> str:\n",
        "    if not route:\n",
        "        return \"\"\n",
        "    return \"Y\" if (\"GPT_\" in route or \"__GPT_\" in route) else \"N\"\n",
        "\n",
        "def derive_irrelevant_reason(failed_criteria: List[str]) -> str:\n",
        "    if not failed_criteria:\n",
        "        return \"\"\n",
        "    mapping = {\n",
        "        \"single_trial_EEG\": \"Not single-trial EEG (or missing EEG/ERP token + single-trial concept)\",\n",
        "        \"human_participants\": \"Human participants not explicitly stated\",\n",
        "        \"non_clinical_sample\": \"Non-clinical/healthy sample not explicitly stated\",\n",
        "    }\n",
        "    return \"; \".join(mapping.get(x, x) for x in failed_criteria)\n",
        "\n",
        "def split_psychometric_keywords(out: Dict[str, Any]) -> Tuple[str, str]:\n",
        "    matched = out.get(\"step2_psychometrics\", {}).get(\"matched_keywords\", []) or []\n",
        "    if not isinstance(matched, list):\n",
        "        matched = [str(matched)]\n",
        "\n",
        "    final_cls = out.get(\"final_classification\", \"\")\n",
        "    psycho_reported = out.get(\"step2_psychometrics\", {}).get(\"psychometrics_reported\", False)\n",
        "\n",
        "    keywords_main = \", \".join(map(str, matched)) if matched else \"\"\n",
        "\n",
        "    if psycho_reported and final_cls != \"Relevant-with-psychometrics\":\n",
        "        keywords_unrelated = keywords_main\n",
        "    else:\n",
        "        keywords_unrelated = \"\"\n",
        "\n",
        "    return keywords_main, keywords_unrelated\n"
      ],
      "metadata": {
        "id": "Rbl1CmswRLyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BLOCK (5) SAVE FILTERED OUTPUT (CSV)\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    pdfs = sorted(glob.glob(os.path.join(PDF_DIR, \"*.pdf\")))\n",
        "    if not pdfs:\n",
        "        raise RuntimeError(f\"No PDFs found in {PDF_DIR}. Upload PDFs to /content/pdfs in Colab.\")\n",
        "\n",
        "    rows: List[Dict[str, Any]] = []\n",
        "\n",
        "    for path in tqdm(pdfs, desc=\"Hybrid classify\"):\n",
        "        fname = os.path.basename(path)\n",
        "\n",
        "        rec: Dict[str, Any] = {\n",
        "            \"title\": \"\",\n",
        "            \"file\": fname,\n",
        "            \"used_text_type\": \"\",\n",
        "            \"route\": \"\",\n",
        "            \"final_classification\": \"\",\n",
        "            \"Relevant Y/N\": \"\",\n",
        "            \"Irrelevant Reason\": \"\",\n",
        "            \"Psychometrics Y/N\": \"\",\n",
        "            \"Keywords\": \"\",\n",
        "            \"Psychometric keywords mentioned in methods or results section unrelated to EEG quality\": \"\",\n",
        "            \"sent_to_gpt (Y/N)\": \"\",\n",
        "            \"gpt_output_json\": \"\",\n",
        "        }\n",
        "        rec[\"title\"] = extract_title_from_pdf(path)\n",
        "\n",
        "        try:\n",
        "            raw = extract_text_from_pdf(path, MAX_PAGES_TO_READ)\n",
        "            sections = extract_AMR(raw)\n",
        "            model_input, used = build_model_input(sections, raw)\n",
        "            rec[\"used_text_type\"] = used\n",
        "\n",
        "            if not model_input:\n",
        "                raise ValueError(\"Empty extracted text\")\n",
        "\n",
        "            # --- Step 1 via Ollama ---\n",
        "            step1 = ollama_step1(model_input)\n",
        "\n",
        "            # If Ollama output not verifiable -> borderline -> full GPT\n",
        "            if not evidence_is_verifiable(step1):\n",
        "                rec[\"route\"] = \"GPT_full_borderline\"\n",
        "                out = openai_full_classify(model_input)\n",
        "\n",
        "            else:\n",
        "                # Verified Step1; accept Ollama for Step1\n",
        "                if not (step1[\"single_trial_EEG\"] and step1[\"human_participants\"] and step1[\"non_clinical_sample\"]):\n",
        "                    rec[\"route\"] = \"Ollama_verified_Irrelevant\"\n",
        "                    out = {\n",
        "                        \"final_classification\": \"Irrelevant\",\n",
        "                        \"step1_relevance\": {\n",
        "                            \"single_trial_EEG\": step1[\"single_trial_EEG\"],\n",
        "                            \"human_participants\": step1[\"human_participants\"],\n",
        "                            \"non_clinical_sample\": step1[\"non_clinical_sample\"],\n",
        "                            \"failed_criteria\": step1[\"failed_criteria\"],\n",
        "                        },\n",
        "                        \"step2_psychometrics\": {\"psychometrics_reported\": False, \"matched_keywords\": []},\n",
        "                        \"evidence_notes\": {\n",
        "                            \"single_trial_EEG_evidence\": step1[\"evidence\"][\"single_trial_EEG_evidence\"],\n",
        "                            \"human_sample_evidence\": step1[\"evidence\"][\"human_sample_evidence\"],\n",
        "                            \"non_clinical_evidence\": step1[\"evidence\"][\"non_clinical_evidence\"],\n",
        "                            \"psychometrics_evidence\": \"not reported\",\n",
        "                        }\n",
        "                    }\n",
        "                else:\n",
        "                    rec[\"route\"] = \"Ollama_verified_Step1__GPT_Step2\"\n",
        "                    out = openai_step2_only(model_input, step1)\n",
        "\n",
        "            # --- Fill CSV fields ---\n",
        "            rec[\"final_classification\"] = out[\"final_classification\"]\n",
        "            rec[\"Relevant Y/N\"] = \"Y\" if out[\"final_classification\"] != \"Irrelevant\" else \"N\"\n",
        "\n",
        "            failed = out.get(\"step1_relevance\", {}).get(\"failed_criteria\", []) or []\n",
        "            rec[\"Irrelevant Reason\"] = (\n",
        "                derive_irrelevant_reason(failed)\n",
        "                if out[\"final_classification\"] == \"Irrelevant\"\n",
        "                else \"\"\n",
        "            )\n",
        "\n",
        "            rec[\"Psychometrics Y/N\"] = yn(out.get(\"step2_psychometrics\", {}).get(\"psychometrics_reported\", False))\n",
        "\n",
        "            kw_main, kw_unrel = split_psychometric_keywords(out)\n",
        "            rec[\"Keywords\"] = kw_main\n",
        "            rec[\"Psychometric keywords mentioned in methods or results section unrelated to EEG quality\"] = kw_unrel\n",
        "\n",
        "            rec[\"sent_to_gpt (Y/N)\"] = is_sent_to_gpt(rec[\"route\"])\n",
        "            rec[\"gpt_output_json\"] = json.dumps(out, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            rec[\"route\"] = \"ERROR\"\n",
        "            rec[\"final_classification\"] = \"ERROR\"\n",
        "            rec[\"Relevant Y/N\"] = \"\"\n",
        "            rec[\"Irrelevant Reason\"] = f\"ERROR: {str(e)}\"\n",
        "            rec[\"Psychometrics Y/N\"] = \"\"\n",
        "            rec[\"Keywords\"] = \"\"\n",
        "            rec[\"Psychometric keywords mentioned in methods or results section unrelated to EEG quality\"] = \"\"\n",
        "            rec[\"sent_to_gpt (Y/N)\"] = \"N\"\n",
        "            rec[\"gpt_output_json\"] = \"\"\n",
        "\n",
        "        rows.append(rec)\n",
        "\n",
        "    cols = [\n",
        "        \"title\",\n",
        "        \"file\",\n",
        "        \"used_text_type\",\n",
        "        \"route\",\n",
        "        \"final_classification\",\n",
        "        \"Relevant Y/N\",\n",
        "        \"Irrelevant Reason\",\n",
        "        \"Psychometrics Y/N\",\n",
        "        \"Keywords\",\n",
        "        \"Psychometric keywords mentioned in methods or results section unrelated to EEG quality\",\n",
        "        \"sent_to_gpt (Y/N)\",\n",
        "        \"gpt_output_json\",\n",
        "    ]\n",
        "\n",
        "    pd.DataFrame(rows, columns=cols).to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "    print(f\"âœ… Done. Saved {OUT_CSV}\")\n",
        "\n",
        "# Run\n",
        "main()\n"
      ],
      "metadata": {
        "id": "dnN_K6UyROhy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}